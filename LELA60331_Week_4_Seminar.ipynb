{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ada7675f",
      "metadata": {
        "id": "ada7675f"
      },
      "source": [
        "# LELA60331 Computational Linguistics 1 Week 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90da35a9",
      "metadata": {
        "id": "90da35a9"
      },
      "source": [
        "This week we are going to look at vector-based models of word meaning. I am first of all going to have to introduce  a Python library called Numpy (https://numpy.org/devdocs/user/absolute_beginners.html).\n",
        "\n",
        "### Numpy\n",
        "\n",
        "Numpy is widely used for representing and processing arrays, including multidimensional arrays (known to us as Vectors/Matrices/Tensors). It is fast, intuitive and has lots of helpful built-in functions (we will make use of some of these later in the semester).\n",
        "\n",
        "To use numpy we need to import it as follows. The naming of numpy as np is a widely-used convention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "971f666e",
      "metadata": {
        "id": "971f666e"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c38f9d",
      "metadata": {
        "id": "a7c38f9d"
      },
      "source": [
        "We can create empty numpy arrays as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6e5e2a",
      "metadata": {
        "id": "9d6e5e2a",
        "outputId": "affa4f7a-1bb8-4107-d91c-56228b88b415"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0.])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For a 1 dimensional colarray\n",
        "np.zeros(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bb2919d",
      "metadata": {
        "id": "8bb2919d",
        "outputId": "e773d8d3-e3ba-4e17-9880-0a1f0ee44cba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For a 2 dimensional array\n",
        "np.zeros((4, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2657b7",
      "metadata": {
        "id": "ce2657b7"
      },
      "source": [
        "We can also create them from Python lists as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd4ec01",
      "metadata": {
        "id": "ccd4ec01",
        "outputId": "fcbcec21-9003-4ca3-b19d-ada4ad5cc4c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 2, 3, 5])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example vector\n",
        "np.array([9,2,3,5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e79c1cc7",
      "metadata": {
        "id": "e79c1cc7",
        "outputId": "11e02991-428b-464f-b18f-0dafc73418be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[9, 2, 3, 5],\n",
              "       [4, 6, 7, 3]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example rank 2 tensor (specificaly a 2x4 matrix)\n",
        "np.array(([9,2,3,5],[4,6,7,3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b85e46",
      "metadata": {
        "id": "38b85e46",
        "outputId": "dac54c01-3dc4-4527-a3c3-5f74686ba364"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0, 1, 2, 3],\n",
              "        [4, 5, 6, 7]],\n",
              "\n",
              "       [[0, 1, 2, 3],\n",
              "        [4, 5, 6, 7]],\n",
              "\n",
              "       [[0, 1, 2, 3],\n",
              "        [4, 5, 6, 7]]])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example rank 3 tensor 3x2x4\n",
        "np.array([[[0, 1, 2, 3],[4, 5, 6, 7]],[[0, 1, 2, 3],[4, 5, 6, 7]],[[0 ,1 ,2, 3],[4, 5, 6, 7]]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff176ea1",
      "metadata": {
        "id": "ff176ea1"
      },
      "source": [
        "The arrays must be rectangular, not ragged, or you will see the following error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9a79791",
      "metadata": {
        "id": "e9a79791",
        "outputId": "c06aeb24-7b37-4d88-a9cf-04715ed7dd24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rq/s77s9qjj1m339ks4ks7kkgyr0000gr/T/ipykernel_8602/1802741343.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  np.array(([9,2,3,5],[4,6,7,3],[5,7,1,2,7]))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([list([9, 2, 3, 5]), list([4, 6, 7, 3]), list([5, 7, 1, 2, 7])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3-dimensional array\n",
        "np.array(([9,2,3,5],[4,6,7,3],[5,7,1,2,7]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1ec48d",
      "metadata": {
        "id": "1f1ec48d"
      },
      "source": [
        "Just as with Python lists we can use indices to find individual values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441da308",
      "metadata": {
        "id": "441da308",
        "outputId": "572f2318-c8d7-4f69-c6d9-25867efa3402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=np.array([9,2,3,5])\n",
        "a[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c4a2f0",
      "metadata": {
        "id": "56c4a2f0"
      },
      "source": [
        "And ranges:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce4d67f",
      "metadata": {
        "id": "5ce4d67f",
        "outputId": "84fa45b9-21ae-42ff-dd2a-8d4f9df87871"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7554d40",
      "metadata": {
        "id": "c7554d40"
      },
      "source": [
        "We can do the same for multidimensional arrays. Indexes should be in the order of nesting. So for a rank 2 tensor the row index comes first and the column second:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a349925",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a349925",
        "outputId": "0f3a84b8-4b4b-40e9-d61a-c7e44d09d926"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=np.array(([9, 2, 3, 5],\n",
        "       [4, 6, 7, 3],\n",
        "       [5, 7, 1, 2]))\n",
        "a[1,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NnpI4piTiONt",
      "metadata": {
        "id": "NnpI4piTiONt"
      },
      "source": [
        "We can assign values to particular positions in our tensor using indices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0gdNA5noiV2O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gdNA5noiV2O",
        "outputId": "685878e8-79f4-43a2-f91c-cd35af6151e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1000    2    3    5]\n",
            " [   4    6    7    3]\n",
            " [   5 2000    1    2]]\n"
          ]
        }
      ],
      "source": [
        "a[0,0] = 1000\n",
        "a[2,1] = 2000\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d4e258",
      "metadata": {
        "id": "c9d4e258"
      },
      "source": [
        "For vectors we can perform the operations that we learned about in our lecture as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbac1a2",
      "metadata": {
        "id": "afbac1a2",
        "outputId": "5c603474-58de-4404-deda-6d66f48a214f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9 2]\n",
            "[1 2]\n",
            "[10  4]\n"
          ]
        }
      ],
      "source": [
        "# Vector addition\n",
        "a = np.array(([9,2,3,5]))\n",
        "b = np.array(([1,2,3,4]))\n",
        "c=a+b\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66918d14",
      "metadata": {
        "id": "66918d14",
        "outputId": "84b50d40-6d84-4ab1-c7b6-62f39e477c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9 2 3 5]\n",
            "[1 2 3 4]\n",
            "[8 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Vector subtraction\n",
        "a = np.array(([9,2,3,5]))\n",
        "b = np.array(([1,2,3,4]))\n",
        "c=a-b\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88746e5",
      "metadata": {
        "id": "a88746e5",
        "outputId": "5d2f2da3-17dd-40a8-ce09-70c8ceda086e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9 2 3 5]\n",
            "[1 2 3 4]\n",
            "[ 9  4  9 20]\n",
            "42\n"
          ]
        }
      ],
      "source": [
        "# Dot product\n",
        "a = np.array(([9,2,3,5]))\n",
        "b = np.array(([1,2,3,4]))\n",
        "c=a*b\n",
        "dp=sum(c)\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)\n",
        "print(dp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f556a48",
      "metadata": {
        "id": "8f556a48"
      },
      "source": [
        "Problem 1: Write the code to calculate the cosine of the angle between vector a and vector b. You might need to refer to your lecture notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8da4d8",
      "metadata": {
        "id": "ab8da4d8"
      },
      "outputs": [],
      "source": [
        "a = np.array(([9,2,3,5]))\n",
        "b = np.array(([1,2,3,4]))\n",
        "cosine = ??????"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_tlmiFQjfwMi",
      "metadata": {
        "id": "_tlmiFQjfwMi"
      },
      "source": [
        "### Building Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b939aded",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b939aded",
        "outputId": "0d26ad7b-4803-4047-ac5f-eb38b6e0340e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-10-14 10:41:00--  https://www.gutenberg.org/files/2554/2554-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201520 (1.1M) [text/plain]\n",
            "Saving to: ‘2554-0.txt.2’\n",
            "\n",
            "2554-0.txt.2        100%[===================>]   1.15M  3.10MB/s    in 0.4s    \n",
            "\n",
            "2024-10-14 10:41:01 (3.10 MB/s) - ‘2554-0.txt.2’ saved [1201520/1201520]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "# download from from the internt\n",
        "!wget https://www.gutenberg.org/files/2554/2554-0.txt\n",
        "# read in the file\n",
        "f = open('2554-0.txt')\n",
        "c_and_p = f.read()\n",
        "# select the first chapter - possible because I determined range\n",
        "c_and_p = c_and_p[5464:]\n",
        "# convert text to lower case\n",
        "c_and_p=c_and_p.lower()\n",
        "c_and_p=re.sub('\\n',' ', c_and_p)\n",
        "c_and_p=re.sub('[^a-z ]','', c_and_p)\n",
        "c_and_p=re.split(\" \", c_and_p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf7a664",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebf7a664",
        "outputId": "fda975d4-ae15-4d13-839d-b01a64789447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['an', 'exceptionally', 'hot', 'evening', 'early', 'in', 'july', 'a', 'young']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c_and_p[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bfcf79",
      "metadata": {
        "id": "33bfcf79"
      },
      "outputs": [],
      "source": [
        "token_count = len(c_and_p)\n",
        "type_list = list(set(c_and_p))\n",
        "# The type count is the number of unique words. The token count is the total number of words including repetitions.\n",
        "type_count = len(type_list)\n",
        "# We create a matrix in which to store the counts for each word-by-word co-occurence\n",
        "M = np.zeros((type_count, type_count))\n",
        "window_size = 2\n",
        "\n",
        "for i, word in enumerate(c_and_p):\n",
        "            #print(str(i) + word)\n",
        "            # Find the index in the tokenized sentence vector for the beginning of the window (the current token minus window size or zero whichever is the lower)\n",
        "            begin = max(i - window_size, 0)\n",
        "            # Find the index in the tokenized sentence vector for the end of the window (the current token plus window size or the length of the sentence whichever is the lower)\n",
        "            end  = min(i + window_size, token_count)\n",
        "            # Extract the text from beginning of window to the end\n",
        "            context = c_and_p[begin: end + 1]\n",
        "            # Remove the target word from its own window\n",
        "            context.remove(c_and_p[i])\n",
        "            # Find the row for the current target word\n",
        "            current_row = type_list.index(c_and_p[i])\n",
        "            # Iterate over the window for this target word\n",
        "            for token in context:\n",
        "                # Find the ID and hence the column index for the current token\n",
        "                current_col = type_list.index(token)\n",
        "                # Add 1 to the current context word dimension for the current target word\n",
        "                M[current_row, current_col] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1YQ4NRDBrGFo",
      "metadata": {
        "id": "1YQ4NRDBrGFo"
      },
      "source": [
        "Problem 2: Calculate the cosine between \"walk\" and \"run\", and between \"walk\" and \"shine\". What does the outcome tell us?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EoaXoRczhqbi",
      "metadata": {
        "id": "EoaXoRczhqbi"
      },
      "outputs": [],
      "source": [
        "w1 = \"walk\"\n",
        "w2 = \"run\"\n",
        "w3 = \"shine\"\n",
        "w1_index = type_list.index(w1)\n",
        "w2_index = type_list.index(w2)\n",
        "w3_index = type_list.index(w3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained embeddings\n",
        "\n",
        "Vectors are best when learned from very large text collections. However learning such vectors, particular using neural network methods rather than simple counting, is very computationally intensive. As a result most people make use of pretrained embeddings such as those found at\n",
        "\n",
        "https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "or\n",
        "\n",
        "https://nlp.stanford.edu/projects/glove/"
      ],
      "metadata": {
        "id": "G20YY35vjV53"
      },
      "id": "G20YY35vjV53"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z2ZU1KzaFWQ",
        "outputId": "0e76ffba-fac0-491f-ca58-903ca21502c4"
      },
      "id": "0z2ZU1KzaFWQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-14 16:04:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-10-14 16:04:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-10-14 16:04:38--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.14MB/s    in 2m 40s  \n",
            "\n",
            "2024-10-14 16:07:18 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Ikqqi2f8MQ",
        "outputId": "55ba7edd-1f82-49dd-b9a9-d6749966cbae"
      },
      "id": "l0Ikqqi2f8MQ",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "embedding_file = 'glove.6B.100d.txt'\n",
        "#embedding_file = f.read()\n",
        "embeddings=[]\n",
        "type_list=[]\n",
        "with open(embedding_file) as fp:\n",
        "            for line in fp.readlines():\n",
        "                line = line.split(\" \")\n",
        "                word = line[0]\n",
        "                vec = np.array([float(x) for x in line[1:]])\n",
        "                type_list.append(word)\n",
        "                embeddings.append(vec)\n",
        "M=np.array((embeddings))"
      ],
      "metadata": {
        "id": "grtFYZDcfrvZ"
      },
      "id": "grtFYZDcfrvZ",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = \"football\"\n",
        "w2 = \"rugby\"\n",
        "w3 = \"cricket\"\n",
        "w1_index = type_list.index(w1)\n",
        "w2_index = type_list.index(w2)\n",
        "w3_index = type_list.index(w3)\n",
        "w1_vec=M[w1_index,]\n",
        "w2_vec=M[w2_index,]\n",
        "w3_vec=M[w3_index,]"
      ],
      "metadata": {
        "id": "P190dF8Kq3VW"
      },
      "id": "P190dF8Kq3VW",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem . Calculate the cosine between the words above. What do the cosine values tell us?"
      ],
      "metadata": {
        "id": "6WYSDJLF7h2l"
      },
      "id": "6WYSDJLF7h2l"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYsyFSRJrYmy"
      },
      "id": "SYsyFSRJrYmy",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(M)"
      ],
      "metadata": {
        "id": "gutnPC3Dv-KV"
      },
      "id": "gutnPC3Dv-KV",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=\"football\"\n",
        "w_index = type_list.index(w)\n",
        "w_vec = M[w_index,]\n",
        "for i in nbrs.kneighbors([w_vec])[1][0]:\n",
        "  print(type_list[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgcxDOU70gYO",
        "outputId": "fdc45421-4b58-4ca7-e33f-1fbbdcefa320"
      },
      "id": "kgcxDOU70gYO",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "football\n",
            "soccer\n",
            "basketball\n",
            "league\n",
            "rugby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 3. Find some examples where the system fails and explain why you think it has done so."
      ],
      "metadata": {
        "id": "144-ZuZ37R9L"
      },
      "id": "144-ZuZ37R9L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analogical reasoning"
      ],
      "metadata": {
        "id": "3U1nSPzz6637"
      },
      "id": "3U1nSPzz6637"
    },
    {
      "cell_type": "markdown",
      "id": "47e0b00f-2595-4402-8492-54e0ee364824",
      "metadata": {
        "id": "47e0b00f-2595-4402-8492-54e0ee364824"
      },
      "source": [
        "Another semantic property of embeddings is their ability to capture relational meanings. In an important early vector space model of cognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model for solving simple analogy problems of the form a is to b as a* is to what?. In such problems, a system given a problem like apple:tree::grape:?, i.e., apple is to tree as  grape is to , and must fill in the word vine.\n",
        "\n",
        "In the parallelogram model, the vector from the word apple to the word tree (= tree − apple) is added to the vector for grape (grape); the nearest word to that point is returned.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4: Complete the code below so that it solves the analogical reasoning problem. Come up with a analogical reasoning problem of your own and use the code to solve it."
      ],
      "metadata": {
        "id": "RoEUVpho6bY_"
      },
      "id": "RoEUVpho6bY_"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "065739ee-7ef2-4471-b33e-6d61c41cf7f2",
      "metadata": {
        "id": "065739ee-7ef2-4471-b33e-6d61c41cf7f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcbd853-b559-4a3e-bd37-99439ea4bc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tree\n",
            "grape\n",
            "vines\n",
            "vine\n",
            "trees\n"
          ]
        }
      ],
      "source": [
        "w1 = \"apple\"\n",
        "w2 = \"tree\"\n",
        "w3 = \"grape\"\n",
        "w1_index = type_list.index(w1)\n",
        "w2_index = type_list.index(w2)\n",
        "w3_index = type_list.index(w3)\n",
        "w1_vec = M[w1_index,]\n",
        "w2_vec = M[w2_index,]\n",
        "w3_vec = M[w3_index,]\n",
        "\n",
        "spatial_relationship = ???\n",
        "w4_vec = ???\n",
        "nbrs.kneighbors([w4_vec])\n",
        "for i in nbrs.kneighbors([w4_vec])[1][0]:\n",
        "  print(type_list[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}